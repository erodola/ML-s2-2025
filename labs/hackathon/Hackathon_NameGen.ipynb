{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For this task, you are going to train a name generator! Ever wondered where **Gwyneth** Paltrow got her name, or how Hawaiian woman Janice **Keihanaikukauakahihuliheekahaunaele** came to be? Probably from this very generator.\n",
        "\n",
        "Let's get going!"
      ],
      "metadata": {
        "id": "XlIKBSHy42lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall pipeline\n",
        "\n",
        "- **Training**\n",
        "\n",
        "  You must implement a model that, given the beginning of a word, predicts the next letter.\n",
        "\n",
        "  For example, if the model `M` is trained on the word `\"house\"`, the trained model should output `M(\"h\") = \"o\"`, `M(\"o\") = \"u\"`, and so on.\n",
        "\n",
        "  Of course, the model will be trained on an entire dataset of words. Therefore, the output of `M(\"h\")` should be *not* deterministic, meaning that ***each time you run the trained model, you should get a different result***.\n",
        "\n",
        "- **Inference**\n",
        "\n",
        "  At test time, the model generates only one new letter, given an input letter.\n",
        "\n",
        "  However, you can still generate entire words by an approach that is as simple as it's weird-sounding: *ancestral sampling*:\n",
        "\n",
        "  1. Select an initial letter, say `\"b\"`.\n",
        "  2. Predict the next letter, say `M(\"b\") = \"r\"`.\n",
        "  3. Concatenate: `\"br\"`.\n",
        "  4. Iterate: go back to step 2, and predict `M(\"r\") = \"e\"`.\n",
        "  5. Concatenate: `\"bre\"`.\n",
        "  6. Keep going, you might eventually get the word `\"bread\"`.\n",
        "\n",
        "- **Delimiters**\n",
        "\n",
        "  Of course, ancestral sampling will keep generating *ad infinitum*.\n",
        "\n",
        "  To avoid this, you also want to train the model to *end* the generation.\n",
        "\n",
        "  This is easily done: simply take your training data and augment it with beginning / end delimiters:\n",
        "\n",
        "  `\"house\" -> \".house.\"`\n",
        "\n",
        "  We chose `\".\"` here, but you can choose your own.\n",
        "\n",
        "  This way, you can ask the model to create a new word completely from scratch, by simply starting inference with `M(\".\") = ...`. And you can stop generating whenever you get `M(...) = \".\"`."
      ],
      "metadata": {
        "id": "L1L4xICpEius"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What you'll need\n",
        "\n",
        "- A list of names: your training data (*see names.txt*)\n",
        "- A way of encoding names to numbers, and viceversa\n",
        "- A model that generates new names (duh)"
      ],
      "metadata": {
        "id": "MLdOZLsP-oj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # let's do this here, to break the wall of text\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "5fCItyfJ_LRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training data\n",
        "\n",
        "Download the file *names.txt* from the course GitHub page.\n",
        "\n",
        "From the sidebar on the left, click on the folder icon at the very bottom.\n",
        "\n",
        "Drag the *human_names.txt* and *pokemon_names.txt* files into the folder and wait for the upload to complete."
      ],
      "metadata": {
        "id": "A6_exmclIyJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = open('human_names.txt', 'r').read().splitlines()\n",
        "\n",
        "len(names)  # should be 32033 for human names, 1302 for PokÃ©mon names"
      ],
      "metadata": {
        "id": "hn6T-BX3IyJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Name encoding and decoding\n",
        "\n",
        "Your trained model must be able to digest and process text characters. You'll do this by writing a simple encoder/decoder such that:\n",
        "\n",
        "```\"hello\" -> [13, 2, 5, 5, 7]```\n",
        "\n",
        "...and of course, the opposite direction.\n",
        "\n",
        "The specific numbers are not important, but you need your `encode` and `decode` functions to behave correctly:\n",
        "\n",
        "```decode(encode(s)) == s```\n",
        "\n",
        "for any string `s`."
      ],
      "metadata": {
        "id": "LNh7M2Qa525O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do it here"
      ],
      "metadata": {
        "id": "nLCDqB_vvymY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and data loaders\n",
        "\n",
        "The training data should simply be a bunch of pairs `(char_in, char_out)`, since you want `M(char_in) = char_out`."
      ],
      "metadata": {
        "id": "kCrskBwcKSS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data here: this will be wrapped in a Dataset in the next cell."
      ],
      "metadata": {
        "id": "I33LhSoQLIZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create your `NGramDataset` class and `DataLoader`s for training, validation and test:"
      ],
      "metadata": {
        "id": "h__HWp6nCV1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "N8c6CO2mCivb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "Now create your training model!"
      ],
      "metadata": {
        "id": "emTxd35BL6_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "c3YUJqfHMGJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "Time to train!"
      ],
      "metadata": {
        "id": "_Pcjr_6YMz67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "FLKYwNOMM1Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "Test your model and generate new crazy names!"
      ],
      "metadata": {
        "id": "jKuF1NglNSuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "6rRNZs11NWw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Larger context\n",
        "\n",
        "Now that you have a working basic model, generalize it so that it can take as input *more than one character*; this should improve the quality of the generated names!\n",
        "\n",
        "For example, using a context length of `3`:\n",
        "\n",
        "`M(\".an\") = \"t\"`\n",
        "\n",
        "...may eventually get you `\"anthony\"`, because the inference steps see a longer context that can better condition the generation.\n",
        "\n",
        "Instead, our current context length of `1`:\n",
        "\n",
        "`M(\".\") = \"a\"`\n",
        "\n",
        "...may diverge and generate unrealistic names like `axyzyll`."
      ],
      "metadata": {
        "id": "NO8BcUQ6Niun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "WT877xtNOxPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PokÃ©mon names\n",
        "\n",
        "We managed to generate these artificial PokÃ©mon names:\n",
        "- beakwily\n",
        "- mordar\n",
        "- dortytel\n",
        "- bymanlona\n",
        "- amlozinder\n",
        "\n",
        "Can you do better than us? ðŸ˜‡\n",
        "\n",
        "Download the *pokemon_names.txt* file from the course webpage and try to come up with an appropriate solution to beat our names!\n",
        "\n",
        "Go catch them all!"
      ],
      "metadata": {
        "id": "7Kcci5k1z0uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "TnwArTGWz16o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}